{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1nuRsQEwzd4p"
   },
   "source": [
    "# Convolutional Neural Network for Handwritten Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTXGrUsyzoE4"
   },
   "source": [
    "**Team : Swaggle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZ5iRptXz9bw"
   },
   "source": [
    "**Members: **\n",
    "\n",
    "*   Rashik Habib\n",
    "*   Josh Lui\n",
    "*   Daniel Lutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99UtfdyY9gxi"
   },
   "source": [
    "(cell #0) Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-Jelv8vm9Ud4"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from google.colab import files\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K56MM81ZzR_x"
   },
   "source": [
    "(cell #1) Setup Google Drive with PyDrive to load data (if using Google Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EP-DDS7GRJCX"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZPkiHQRU3MF"
   },
   "source": [
    "(cell #2a) Load datasets, semi-preprocess and store them in local variables (if loading from Koustuv's website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xWPyZ68XU1x9"
   },
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "\n",
    "URL_ENDPOINT = \"http://cs.mcgill.ca/~ksinha4/datasets/kaggle/\"\n",
    "\n",
    "train_x = np.loadtxt(URL_ENDPOINT+\"train_x.csv\", delimiter=\",\", dtype=int)\n",
    "train_y = np.loadtxt(URL_ENDPOINT+\"train_y.csv\", delimiter=\",\", dtype=int)\n",
    "test_x = np.loadtxt(URL_ENDPOINT+\"test_x.csv\", delimiter=\",\", dtype=int)\n",
    "\n",
    "# Semi-preprocessing\n",
    "\n",
    "from skimage import measure\n",
    "from skimage import filters\n",
    "\n",
    "pad_on = 1\n",
    "\n",
    "separator_threshold = 235\n",
    "\n",
    "# Pad the image with zeros to simplify DFS \n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 0)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n",
    "    return vector\n",
    "\n",
    "# Return an integer giving the largest bounding square for a digit - O(64 x 64)\n",
    "def bounding_square(image, digit_eq):\n",
    "    min_x = 100000\n",
    "    min_y = 100000\n",
    "    max_x = -100000\n",
    "    max_y = -100000\n",
    "\n",
    "    for x in range(image.shape[1]):\n",
    "        for y in range(image.shape[0]):\n",
    "            \n",
    "            if image[x][y] == digit_eq:\n",
    "                \n",
    "                if x < min_x:\n",
    "                    min_x = x\n",
    "                if x > max_x:\n",
    "                    max_x = x\n",
    "                if y < min_y:\n",
    "                    min_y = y\n",
    "                if y > max_y:\n",
    "                    max_y = y\n",
    "    \n",
    "    \n",
    "    if (max_x - min_x) > (max_y - min_y):\n",
    "        return (max_x - min_x)**2\n",
    "    else:\n",
    "        return (max_y - min_y)**2\n",
    "                \n",
    "# Find the integer representative for the largest digit in the image\n",
    "def largest_digit_eq(image):\n",
    "    digit_eqs = np.unique(image)\n",
    "    digits = digit_eqs.shape[0]     #includes the background (padding ensures 0th element represemts background)\n",
    "    \n",
    "    # error: no digits recognized\n",
    "    if digits < 2:\n",
    "        return -1\n",
    "    \n",
    "    # only 1 digit, must be the largest\n",
    "    elif digits == 2:\n",
    "        return digit_eqs[1]\n",
    "    \n",
    "    else:\n",
    "        max_bounding_square = -1\n",
    "        essential_digit = -1\n",
    "        \n",
    "        for digit_eq in range(1, digits):\n",
    "            if  bounding_square(image, digit_eq) > max_bounding_square:\n",
    "                max_bounding_square = bounding_square(image, digit_eq)\n",
    "                essential_digit = digit_eq\n",
    "            \n",
    "    return essential_digit\n",
    "\n",
    "# Apply the semi-preprocessing to the loaded examples \n",
    "\n",
    "train_x = train_x.reshape(-1, 64, 64)\n",
    "test_x = test_x.reshape(-1, 64, 64)\n",
    "\n",
    "for i, example_x in enumerate(train_x):\n",
    "    if pad_on:\n",
    "        example_x = np.pad(example_x, 1, pad_with) #becomes (66 x 66)\n",
    "    \n",
    "    # convert all digits above threshold to 255, and the rest to 0, labeling the connected components\n",
    "    # essentially removes the backgound image, keeping only the handwritten digits\n",
    "    example_x[example_x > separator_threshold] = 255\n",
    "    example_x[example_x < separator_threshold] = 0\n",
    "    example_x = measure.label(example_x, connectivity=1)\n",
    "    \n",
    "    # find the largest digit equivalent in the image and keep only its values\n",
    "    # essentially removes digits which are irrelevant\n",
    "    essential_digit = largest_digit_eq(example_x)\n",
    "    example_x[example_x != essential_digit] = 0\n",
    "    example_x[example_x == essential_digit] = 255\n",
    "\n",
    "for i, example_x in enumerate(test_x):\n",
    "    if pad_on:\n",
    "        example_x = np.pad(example_x, 1, pad_with) #becomes (66 x 66)\n",
    "    \n",
    "    # convert all digits above threshold to 255, and the rest to 0, labeling the connected components\n",
    "    # essentially removes the backgound image, keeping only the handwritten digits\n",
    "    example_x[example_x > separator_threshold] = 255\n",
    "    example_x[example_x < separator_threshold] = 0\n",
    "    example_x = measure.label(example_x, connectivity=1)\n",
    "    \n",
    "    # find the largest digit equivalent in the image and keep only its values\n",
    "    # essentially removes digits which are irrelevant\n",
    "    essential_digit = largest_digit_eq(example_x)\n",
    "    example_x[example_x != essential_digit] = 0\n",
    "    example_x[example_x == essential_digit] = 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OU4CIrlTjtkS"
   },
   "source": [
    "(cell #2b) Further pre-process the data by cropping the largest digit, applying blur and rescaling to 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GzBafB4Zjsxx"
   },
   "outputs": [],
   "source": [
    "def crop_minAreaRect(img, rect):\n",
    "\n",
    "    # rotate img\n",
    "    angle = rect[2]\n",
    "    rows,cols = img.shape[0], img.shape[1]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "    img_rot = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "    # rotate bounding box\n",
    "    rect0 = (rect[0], rect[1], 0.0)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    pts = np.int0(cv2.transform(np.array([box]), M))[0]    \n",
    "    pts[pts < 0] = 0\n",
    "\n",
    "    # crop\n",
    "    img_crop = img_rot[pts[1][1]:pts[0][1], \n",
    "                       pts[1][0]:pts[2][0]]\n",
    "\n",
    "    return img_crop\n",
    "\n",
    "# test_x\n",
    "master = np.ones((28,28), dtype=int)\n",
    "\n",
    "for img in test_x:\n",
    "    \n",
    "    # blur the image\n",
    "    kernel = np.ones((2,2),np.float32)/25\n",
    "    dst = cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "    # find contours / rectangle\n",
    "    _,contours,_ = cv2.findContours(dst, 1, 1)\n",
    "    \n",
    "    rect = cv2.minAreaRect(contours[-1])\n",
    "\n",
    "    # crop\n",
    "    dst_croped = crop_minAreaRect(dst, rect)\n",
    "    \n",
    "    # rotate and flip image if needed\n",
    "    if dst_croped.shape[1] > dst_croped.shape[0]:\n",
    "      dst_croped = dst_croped.T\n",
    "      dst_croped = np.flipud(dst_croped)\n",
    "    \n",
    "    # resize image to 28x28\n",
    "    dst_croped = cv2.resize(dst_croped, (28,28))\n",
    "    \n",
    "    master = np.concatenate((master, dst_croped), axis=0)\n",
    "\n",
    "# remove the dummy ones placed at the start\n",
    "test_x = master[28:, :]\n",
    "\n",
    "# train_x\n",
    "master = np.ones((28,28), dtype=int)\n",
    "\n",
    "for img in train_x:\n",
    "    \n",
    "    # blur the image\n",
    "    kernel = np.ones((2,2),np.float32)/25\n",
    "    dst = cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "    # find contours / rectangle\n",
    "    _,contours,_ = cv2.findContours(dst, 1, 1)\n",
    "    \n",
    "    rect = cv2.minAreaRect(contours[-1])\n",
    "\n",
    "    # crop\n",
    "    dst_croped = crop_minAreaRect(dst, rect)\n",
    "    \n",
    "    # rotate and flip image if needed\n",
    "    if dst_croped.shape[1] > dst_croped.shape[0]:\n",
    "      dst_croped = dst_croped.T\n",
    "      dst_croped = np.flipud(dst_croped)\n",
    "    \n",
    "    # resize image to 28x28\n",
    "    dst_croped = cv2.resize(dst_croped, (28,28))\n",
    "    \n",
    "    master = np.concatenate((master, dst_croped), axis=0)\n",
    "\n",
    "# remove the dummy ones placed at the start\n",
    "train_x = master[28:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BeLnE2cPzAGS"
   },
   "source": [
    "(cell #2c) Load the preprocessed files by ID and store them in local variables (if using Google Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TqqggSDsPIdR"
   },
   "outputs": [],
   "source": [
    "# resized : 1ay5-78XLNGEopXIg75Cazi3675tGnynA\n",
    "\n",
    "trainset_x_id = \"1ay5-78XLNGEopXIg75Cazi3675tGnynA\"\n",
    "downloaded = drive.CreateFile({'id': trainset_x_id})\n",
    "downloaded.GetContentFile('resized_edited_train_x.csv') \n",
    "train_x = np.loadtxt('resized_edited_train_x.csv', delimiter=',', dtype=np.uint8)\n",
    "\n",
    "trainset_y_id = '16mC77GcpoUb1KhGzAxfJMX2-kV1Mgl1E'\n",
    "downloaded = drive.CreateFile({'id': trainset_y_id})\n",
    "downloaded.GetContentFile('train_y.csv') \n",
    "train_y = np.loadtxt('train_y.csv', delimiter=',', dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtcEblnc15oi"
   },
   "source": [
    "(cell #3) Split the data (if validation required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8wYIj9DsAc3M"
   },
   "outputs": [],
   "source": [
    "test_x = train_x[0:5000, :]\n",
    "test_y = train_y[0:5000]\n",
    "train_x = train_x[5000:50000, :]\n",
    "train_y = train_y[5000:50000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceceSygg2MEp"
   },
   "source": [
    "(cell #4) Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hfp31t5o6KMd"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Performance: 92.5 %\n",
    "Architecture: conv(32, 3x3) -> conv(32, 3x3) -> pool(2x2, 2) -> dropout(15%)\n",
    "           -> conv(64, 5x5) -> conv(64, 5x5) -> pool(2x2, 2) -> dropout(15%)\n",
    "           -> conv(128, 7x7) -> conv(128, 7x7) -> conv(128, 7x7) -> pool(2x2, 2) -> dropout(15%)\n",
    "           -> flatten -> FC(128) -> FC(128) -> dropout(25%) -> logits\n",
    "Batch size: 50\n",
    "Steps: 20000\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def CNN(features, labels, mode):\n",
    "    \n",
    "    # Input Layer\n",
    "    # Reshape training data to 4-D tensor and convert to float32\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "    input_layer = tf.cast(input_layer, tf.float32)\n",
    "    \n",
    "    # Convolutional Layers #1\n",
    "    # Computes 32 features using two 3x3 filters with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "   \n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=conv1,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2)\n",
    "    \n",
    "    # Add dropout operation; 0.85 probability that element will be kept\n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=pool1,\n",
    "        rate=0.15,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Convolutional Layers #2\n",
    "    # Computes 64 features using two 5x5 filters.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=conv3,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv4,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2)\n",
    "    \n",
    "    # Add dropout operation; 0.85 probability that element will be kept\n",
    "    dropout2 = tf.layers.dropout(\n",
    "        inputs=pool2,\n",
    "        rate=0.15,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Convolutional Layers #3\n",
    "    # Computes 128 features using three 7x7 filters.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 128]\n",
    "    conv5 = tf.layers.conv2d(\n",
    "        inputs=dropout2,\n",
    "        filters=128,\n",
    "        kernel_size=[7, 7],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    conv6 = tf.layers.conv2d(\n",
    "        inputs=conv5,\n",
    "        filters=128,\n",
    "        kernel_size=[7, 7],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    conv7 = tf.layers.conv2d(\n",
    "        inputs=conv6,\n",
    "        filters=128,\n",
    "        kernel_size=[7, 7],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Pooling Layer #3\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 128]\n",
    "    # Output Tensor Shape: [batch_size, 4, 4, 128]\n",
    "    pool3 = tf.layers.max_pooling2d(\n",
    "        inputs=conv7,\n",
    "        pool_size=[2, 2],\n",
    "        strides=2)\n",
    "    \n",
    "    # Add dropout operation; 0.85 probability that element will be kept\n",
    "    dropout3 = tf.layers.dropout(\n",
    "        inputs=pool3,\n",
    "        rate=0.15,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 4, 4, 128]\n",
    "    # Output Tensor Shape: [batch_size, 4 * 4 * 128]\n",
    "    pool3_flat = tf.reshape(dropout3, [-1, dropout3.shape[1] * dropout3.shape[2] * dropout3.shape[3]])\n",
    "    \n",
    "    # Dense Layer\n",
    "    # Two Densely connected layers with 128 neurons each\n",
    "    # Input Tensor Shape: [batch_size, 4 * 4 * 128]\n",
    "    # Output Tensor Shape: [batch_size, 128]\n",
    "    dense1 = tf.layers.dense(\n",
    "        inputs=pool3_flat,\n",
    "        units=128,\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    dense2 = tf.layers.dense(\n",
    "        inputs=dense1,\n",
    "        units=128,\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Add dropout operation; 0.75 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense2,\n",
    "        rate=0.25,\n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 128]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    \n",
    "    predictions = {\n",
    "    # Generate predictions (for PREDICT and EVAL mode)\n",
    "    \"classes\": tf.argmax(input=logits, axis=1),\n",
    "    # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "    # `logging_hook`.\n",
    "    \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "      return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "      train_op = optimizer.minimize(\n",
    "          loss=loss,\n",
    "          global_step=tf.train.get_global_step())\n",
    "      return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                        loss=loss,\n",
    "                                        train_op=train_op)\n",
    "    \n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss,\n",
    "        eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "train_x = train_x.reshape(-1, 28, 28)  \n",
    "\n",
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "  model_fn=CNN)\n",
    "\n",
    "\"\"\"\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)\n",
    "\"\"\"\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_x},\n",
    "    y=train_y,\n",
    "    batch_size=50,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=20000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-tpcXJZ2bIB"
   },
   "source": [
    "(cell #5) Evaluate the model and print results (if validation required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VfqWS40dm6iL"
   },
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_x},\n",
    "    y=test_y,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "shjPRI06QpId"
   },
   "source": [
    "(cell #6) Import the test set images from Google Drive (if submitting to Kaggle and using Google Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Pkpn3TiXtj35"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "testset_x_id = \"1JIFuYh2WuGfFy9IONaZx0puxfik9jfjF\"\n",
    "downloaded = drive.CreateFile({'id': testset_x_id})\n",
    "downloaded.GetContentFile('resized_edited_test_x.csv') \n",
    "test_x = np.loadtxt('resized_edited_test_x.csv', delimiter=',', dtype=np.uint8)\n",
    "\n",
    "test_x = test_x.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E9qLaCQGQ73e"
   },
   "source": [
    "(cell #7) Predict the results (if submitting to Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AojB0CGejziY"
   },
   "outputs": [],
   "source": [
    "# run the trained classifier model on the test set\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_x},\n",
    "    y=None,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = mnist_classifier.predict(input_fn=eval_input_fn)\n",
    "\n",
    "predictions = []\n",
    "Id = []\n",
    "i=0\n",
    "\n",
    "for obj in eval_results:\n",
    "  Id.append(i)\n",
    "  predictions.append(obj[\"classes\"])\n",
    "  i = i+1\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.reshape(predictions.shape[0], 1)\n",
    "Id = np.array(Id)\n",
    "Id = Id.reshape(Id.shape[0], 1)\n",
    "answers = np.concatenate((Id, predictions), axis=1)\n",
    "\n",
    "# output predictions to a file\n",
    "\n",
    "with open('pred_test_y.csv', 'w') as f:\n",
    "  np.savetxt(f, answers, delimiter=',', header=\"Id,Label\", fmt='%d')\n",
    "\n",
    "files.download('pred_test_y.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Kaggle_CNN.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
